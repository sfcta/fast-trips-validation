{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# format sig figs\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = r'J:\\Projects\\FasTrips\\obs\\output\\OBS_fasttrips_demand_v1.1_stochastic_iter2_nocap_30000'\n",
    "\n",
    "# obs_links_dir = r'R:\\FastTrips\\FT Repo\\All input & output files\\OBS_FToutput.csv'\n",
    "obs_links_dir = r'..\\data\\obs\\obs_links.csv'\n",
    "\n",
    "# Probability threshold for observed paths (are observed paths assigned above/below this value by fast-trips)\n",
    "threshold = 0.3\n",
    "\n",
    "# Compare observed path to pathset based on modes, agency, or route\n",
    "# comparison_field = 'path_modes'\n",
    "comparison_field = 'path_agencies'\n",
    "# comparison_field = 'path_routes'\n",
    "\n",
    "non_transit_modes = ['transfer','walk_access','walk_egress','bike_access','bike_egress',\n",
    "                     'PNR_access','PNR_egress','KNR_access','KNR_egress']\n",
    "transit_mode_list = ['local_bus','commuter_rail','express_bus','ferry','heavy_rail','light_rail','premium_bus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_df(data, unique_fields, record_type=None):\n",
    "    '''Load text data as df, create unique trip record ID, and tag as model/observed record'''\n",
    "    df = pd.read_csv(data)\n",
    "    if record_type != None:\n",
    "        df['record_type'] = record_type    # tag as model/observed record\n",
    "\n",
    "    # Convert all specified unique_fields to string and concatenate as new unique_id field \n",
    "#     df[unique_fields] = pd.DataFrame([df[col].astype('int').astype('str') for col in unique_fields]).T\n",
    "#     df['unique_id'] = df[unique_fields].apply(lambda x: '_'.join(x), axis=1)\n",
    "    df['unique_id'] = df['person_id']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def append(*args):\n",
    "    '''Union dataframes with similar structures'''\n",
    "    df = pd.DataFrame()\n",
    "    for data in args:\n",
    "        df = df.append(data)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_common_records(df1,df2,field):\n",
    "    '''Return dataframe of matching, common records only.\n",
    "       Example, person 1034 exists in df1, but not in df2, so new copy of df1 without 1034 is created\n",
    "    '''\n",
    "    df1 = df1[df1[field].isin(df2[field])]\n",
    "    df2 = df2[df2[field].isin(df1[field])]\n",
    "\n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_transit_agency(df, routes):\n",
    "\n",
    "    df = pd.merge(left=df,right=routes[['route_id','agency_id']],on='route_id',how='left')\n",
    "\n",
    "    df['agency'] = df['agency_id']\n",
    "    df.drop('agency_id',axis=1)\n",
    "    df.fillna(\"\",inplace=True)\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def produce_path_fields(df, group):\n",
    "    '''\n",
    "    Concatenate set of fields for pathset_links, e.g. ('bart caltrain') for 2-leg transit trip\n",
    "    Produce concatenated fields for routes, modes, agencies, all components (stops, modes, & routes)\n",
    "    '''\n",
    "    # create \"path_routes\"\n",
    "\n",
    "    for field in ['route_id','mode','agency','A_id','B_id']:\n",
    "        df[field] = df[field].astype('str')\n",
    "        df[field] = df[field].fillna(\"\")\n",
    "        df[field] = df[field].replace('nan',\"\")\n",
    "\n",
    "    df['path_routes'] = df['route_id'].apply(lambda x: x.strip())\n",
    "    path_routes = pd.DataFrame(df.groupby(group)['path_routes'].apply(lambda x: \"%s\" % ' '.join(x).strip()))\n",
    "    \n",
    "    result_df = pd.DataFrame(index=path_routes.index)\n",
    "    result_df['path_routes'] = path_routes\n",
    "    \n",
    "    # create \"path_modes\"\n",
    "    df['path_modes'] = df['mode'].apply(lambda x: x.strip())\n",
    "    result_df['path_modes'] = pd.DataFrame(df.groupby(group)['mode'].apply(lambda x: \"%s\" % ' '.join(x).strip()))\n",
    "    \n",
    "    # create \"path_agencies\"\n",
    "    df['path_agencies'] = df['agency'].apply(lambda x: x.strip())\n",
    "    result_df['path_agencies'] = pd.DataFrame(df.groupby(group)['agency'].apply(lambda x: \"%s\" % ' '.join(x).strip()))\n",
    "\n",
    "    # Create \"path_components\"\n",
    "    df['path_components'] = df['A_id']+\" \"+df['mode']+\" \"+df['route_id'] +\"_\"+ df['B_id']\n",
    "    df['path_components'] = df['path_components'].apply(lambda x: x.strip())\n",
    "    result_df['path_components'] = pd.DataFrame(df.groupby(group)['path_components'].apply(lambda x: \"%s\" % ' '.join(x).strip()))\n",
    "    \n",
    "    # stop components\n",
    "    df['A_id'] = df['A_id'].astype('str')\n",
    "    df['B_id'] = df['B_id'].astype('str')\n",
    "    df['path_stops'] = df['A_id'] +\" \"+df['B_id']\n",
    "    df['path_stops'] = df['path_stops'].apply(lambda x: x.strip())\n",
    "    result_df['path_stops'] = pd.DataFrame(df.groupby(group)['path_stops'].apply(lambda x: \"%s\" % ' '.join(x).strip()))\n",
    "    # drop repeated records (A_id and B_id overlap as origin and destination nodes for subsequent trips)\n",
    "    result_df['path_stops'] = result_df['path_stops'].apply(lambda row: np.unique(row.split(' ')))\n",
    "    # write out as space separated field\n",
    "    result_df['path_stops'] = result_df['path_stops'].apply(lambda x: \"%s\" % ' '.join(x).strip())\n",
    "    \n",
    "    # Return ID field from index\n",
    "    result_df['unique_id'] = result_df.index.get_level_values(0).values\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "routes = pd.read_csv(r'../data/gtfs/agency_route_1.9.csv')\n",
    "\n",
    "# Load observed and chosenpath_links; add new field designating 'model' or 'observed'\n",
    "obs = load_df(data=obs_links_dir, unique_fields=['person_id','trip_list_id_num'], record_type='observed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fill floats with integers where available, specifically for stop IDs\n",
    "obs['A_id'] = obs['A_id'].fillna(0).astype('int')\n",
    "obs['B_id'] = obs['B_id'].fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chosenpath_links = load_df(data=OUTPUT_DIR + r'\\chosenpaths_links.csv', \n",
    "    unique_fields=['person_id','trip_list_id_num'], record_type='model', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12916658"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chosenpath_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For some reason there are a lot of duplicates\n",
    "# let's drop them for now\n",
    "chosenpath_links = chosenpath_links.drop_duplicates()\n",
    "\n",
    "# Get the last iteration only\n",
    "chosenpath_links = chosenpath_links[chosenpath_links['iteration'] == chosenpath_links['iteration'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add transit agency field to chosenpath_links and pathset_links, based on route_id\n",
    "chosenpath_links = add_transit_agency(df=chosenpath_links, routes=routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chosenpath_links['A_id'] = chosenpath_links['A_id'].fillna(0).astype('int')\n",
    "chosenpath_links['B_id'] = chosenpath_links['B_id'].fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "observed_path = produce_path_fields(obs, group=['unique_id'])\n",
    "modeled_path = produce_path_fields(chosenpath_links, group=['unique_id'])\n",
    "\n",
    "# Make sure we only evaluate the overlapping unique_id records\n",
    "observed_path = observed_path[observed_path['unique_id'].isin(modeled_path['unique_id'].values)]\n",
    "modeled_path = modeled_path[modeled_path['unique_id'].isin(observed_path['unique_id'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build comparison fields for pathset_links\n",
    "- from the description column in pathset_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mode_list(row):\n",
    "\n",
    "    row_array = row.split(' ')\n",
    "    \n",
    "    mode_results = []\n",
    "    \n",
    "    for field in row_array:\n",
    "        if field in transit_mode_list + ['transfer','walk_access','walk_egress']:\n",
    "            mode_results.append(field)\n",
    "\n",
    "    # convert from list into space-seperated string\n",
    "    mode_results = ' '.join(mode_results).strip()\n",
    "\n",
    "    return mode_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def route_list(row):\n",
    "    \"\"\"\n",
    "    if route_only=True, return only the route id from the trip id prepended with route info\n",
    "    otherwise return full route_id_xyz, where xyz is the trip id\n",
    "    \"\"\"\n",
    "    \n",
    "    row_array = row.split(' ')\n",
    "    \n",
    "    route_results = []\n",
    "    \n",
    "    for i in xrange(len(row_array)):\n",
    "        if row_array[i] in transit_mode_list:\n",
    "            route_results.append(\"_\".join(row_array[i+1].split('_')[:-1]))     # Drop last component of field (trip ID)\n",
    "#                 route_results.append(row_array[i+1])\n",
    "            \n",
    "    route_results =  ' '.join(route_results).strip()\n",
    "    \n",
    "    return route_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stop_list(row):\n",
    "    \n",
    "    row_array = row.split(' ')\n",
    "    \n",
    "    # Get the list of transit\n",
    "    trip_with_route_list = []\n",
    "    stop_results = []\n",
    "    \n",
    "    for i in xrange(len(row_array)):\n",
    "        if row_array[i] in transit_mode_list:\n",
    "            # Save this as a field we don't want to include as a stop\n",
    "            trip_with_route_list.append(row_array[i+1])\n",
    "        if row_array[i] not in trip_with_route_list+transit_mode_list+['transfer','walk_access','walk_egress']:\n",
    "            stop_results.append(row_array[i])\n",
    "    \n",
    "    stop_results = ' '.join(stop_results).strip()\n",
    "    \n",
    "    return stop_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def agency_list(row):\n",
    "    \n",
    "    agency_results = []\n",
    "    \n",
    "    # Get list of agencies associated with each transit route\n",
    "    row_array = row.split(' ')\n",
    "    \n",
    "    for route_id in row_array:\n",
    "        agency_results.append(routes[routes['route_id'] == route_id]['agency_id'].values[0])\n",
    "    \n",
    "    agency_results = ' '.join(agency_results).strip()\n",
    "    \n",
    "    return agency_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Mode paths\n",
    "pathset_paths['path_modes'] = pathset_paths['description'].apply(lambda row: mode_list(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Route paths\n",
    "pathset_paths['path_routes'] = pathset_paths['description'].apply(lambda row: route_list(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Stops\n",
    "pathset_paths['path_stops'] = pathset_paths['description'].apply(lambda row: stop_list(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Agencies\n",
    "pathset_paths['path_agencies'] = pathset_paths['path_routes'].apply(lambda row: agency_list(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a stacked csv of observed trip links & model chosenpath_links; export for Tableau\n",
    "chosenpath_links, obs = select_common_records(chosenpath_links, obs,'person_id')\n",
    "chosenpaths_links_with_observed = append(chosenpath_links, obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80814"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # add additional info about the transfer from and to route/agency for tableau maps\n",
    "chosenpaths_links_with_observed['transfer_from_agency'] = chosenpaths_links_with_observed['agency'].shift(1)\n",
    "chosenpaths_links_with_observed['transfer_to_agency'] = chosenpaths_links_with_observed['agency'].shift(-1)\n",
    "\n",
    "chosenpaths_links_with_observed['transfer_from_route'] = chosenpaths_links_with_observed['route_id'].shift(1)\n",
    "chosenpaths_links_with_observed['transfer_to_route'] = chosenpaths_links_with_observed['route_id'].shift(-1)\n",
    "\n",
    "len(chosenpaths_links_with_observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chosenpaths_links_with_observed[['A_id','B_id']] = chosenpaths_links_with_observed[['A_id','B_id']].replace('',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add geography too\n",
    "# Get distance from TAZ to stop\n",
    "walk_access_ft = pd.read_csv(r'R:\\FastTrips\\network_draft1.9\\walk_access_ft.txt')[['taz','stop_id','dist']]\n",
    "\n",
    "chosenpaths_links_with_observed[['A_id','B_id']] = chosenpaths_links_with_observed[['A_id','B_id']].astype('float')\n",
    "\n",
    "chosenpaths_links_with_observed = pd.merge(chosenpaths_links_with_observed, walk_access_ft, \n",
    "                                           left_on=['A_id','B_id'],right_on=['taz','stop_id'],how='left')\n",
    "\n",
    "\n",
    "chosenpaths_links_with_observed['walk_access_dist'] = chosenpaths_links_with_observed['dist']\n",
    "\n",
    "# # Now join for distance from stop to TAZ (egress)\n",
    "chosenpaths_links_with_observed.drop(['taz','stop_id','dist'],axis=1,inplace=True)\n",
    "chosenpaths_links_with_observed = pd.merge(chosenpaths_links_with_observed, walk_access_ft, \n",
    "                                           left_on=['A_id','B_id'],right_on=['stop_id','taz'],how='left')\n",
    "chosenpaths_links_with_observed['walk_egress_dist'] = chosenpaths_links_with_observed['dist']\n",
    "chosenpaths_links_with_observed.drop(['taz','stop_id','dist'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80814"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chosenpaths_links_with_observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lat-long where it's missing for stops\n",
    "stops = pd.read_csv(r'R:\\FastTrips\\network_draft1.9\\stops.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chosenpaths_links_with_observed = pd.merge(chosenpaths_links_with_observed,stops,left_on='A_id',right_on='stop_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         nan\n",
       "1    37.56974\n",
       "2    37.44334\n",
       "3    37.44334\n",
       "4    37.44442\n",
       "5         nan\n",
       "6    37.75156\n",
       "7    37.61499\n",
       "8         nan\n",
       "9    37.77638\n",
       "10   37.58103\n",
       "11        nan\n",
       "12   37.86529\n",
       "13   37.78973\n",
       "14        nan\n",
       "...\n",
       "80799        nan\n",
       "80800   37.69265\n",
       "80801   37.70127\n",
       "80802        nan\n",
       "80803   37.78472\n",
       "80804   37.85413\n",
       "80805        nan\n",
       "80806   37.87262\n",
       "80807   37.75156\n",
       "80808        nan\n",
       "80809   37.85413\n",
       "80810   37.87174\n",
       "80811        nan\n",
       "80812   37.78893\n",
       "80813   37.72115\n",
       "Name: stop_lat, Length: 80814, dtype: float64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosenpaths_links_with_observed['stop_lat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Join again with TAZ since most A_id walk_access trips are TAZ\n",
    "taz = pd.read_csv(r'R:\\FastTrips\\network_draft1.9\\taz_coords.txt')\n",
    "\n",
    "chosenpaths_links_with_observed = pd.merge(chosenpaths_links_with_observed,taz,left_on='A_id',right_on='taz',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fill the nan stop_id with lat and long fields from the TAZ merge\n",
    "chosenpaths_links_with_observed.ix[pd.isnull(chosenpaths_links_with_observed['stop_id'])]['lat'] = \\\n",
    "    chosenpaths_links_with_observed.ix[pd.isnull(chosenpaths_links_with_observed['stop_id'])]['stop_lat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chosenpaths_links_with_observed['stop_lat'].fillna(chosenpaths_links_with_observed['lat'],inplace=True)\n",
    "chosenpaths_links_with_observed['stop_lon'].fillna(chosenpaths_links_with_observed['lon'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chosenpaths_links_with_observed.to_csv(OUTPUT_DIR + '/' + 'chosenpaths_links_with_observed.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Combine the observed and modeled path files\n",
    "df = pd.merge(observed_path, modeled_path, on='unique_id',suffixes=(\"_observed\",\"_model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- compare routes, modes, and agencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build list of routes used in observed and modeled trips\n",
    "df['model_path_route_list'] = df['path_routes_model'].apply(lambda x: x.split(\" \"))\n",
    "df['obs_path_route_list'] = df['path_routes_observed'].apply(lambda x: x.split(\" \"))\n",
    "\n",
    "# Build list of modes used in observed and modeled trips\n",
    "df['model_path_mode_list'] = df['path_modes_model'].apply(lambda x: x.split(\" \"))\n",
    "df['obs_path_mode_list'] = df['path_modes_observed'].apply(lambda x: x.split(\" \"))\n",
    "\n",
    "# Build list of transit agencies used in observed and modeled trips\n",
    "df['model_path_agencies_list'] = df['path_agencies_model'].apply(lambda x: x.split(\" \"))\n",
    "df['obs_path_agencies_list'] = df['path_agencies_observed'].apply(lambda x: x.split(\" \"))\n",
    "\n",
    "# Build list of stops used in observed and modeled trips\n",
    "df['model_path_stops_list'] = df['path_stops_model'].apply(lambda x: x.split(\" \"))\n",
    "df['obs_path_stops_list'] = df['path_stops_observed'].apply(lambda x: x.split(\" \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>trip_list_id_num</th>\n",
       "      <th>linkmode</th>\n",
       "      <th>A_id</th>\n",
       "      <th>B_id</th>\n",
       "      <th>linknum</th>\n",
       "      <th>mode</th>\n",
       "      <th>route_id</th>\n",
       "      <th>agency</th>\n",
       "      <th>record_type</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>path_routes</th>\n",
       "      <th>path_modes</th>\n",
       "      <th>path_agencies</th>\n",
       "      <th>path_components</th>\n",
       "      <th>path_stops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 10---Caltrain---2014</td>\n",
       "      <td> 2</td>\n",
       "      <td>  access</td>\n",
       "      <td>  1249</td>\n",
       "      <td> 14661</td>\n",
       "      <td> 0</td>\n",
       "      <td>    KNR_access</td>\n",
       "      <td>                            </td>\n",
       "      <td>         </td>\n",
       "      <td> observed</td>\n",
       "      <td> 10---Caltrain---2014</td>\n",
       "      <td>                            </td>\n",
       "      <td>    KNR_access</td>\n",
       "      <td>         </td>\n",
       "      <td>                            1249 KNR_access _14661</td>\n",
       "      <td>  1249 14661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 10---Caltrain---2014</td>\n",
       "      <td> 2</td>\n",
       "      <td> transit</td>\n",
       "      <td> 14661</td>\n",
       "      <td> 14673</td>\n",
       "      <td> 1</td>\n",
       "      <td> commuter_rail</td>\n",
       "      <td> Caltrain_Millbrae Palo Alto</td>\n",
       "      <td> caltrain</td>\n",
       "      <td> observed</td>\n",
       "      <td> 10---Caltrain---2014</td>\n",
       "      <td> Caltrain_Millbrae Palo Alto</td>\n",
       "      <td> commuter_rail</td>\n",
       "      <td> caltrain</td>\n",
       "      <td> 14661 commuter_rail Caltrain_Millbrae Palo Alt...</td>\n",
       "      <td> 14661 14673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td> 10---Caltrain---2014</td>\n",
       "      <td> 2</td>\n",
       "      <td>  egress</td>\n",
       "      <td> 14673</td>\n",
       "      <td>  1356</td>\n",
       "      <td> 2</td>\n",
       "      <td>   walk_egress</td>\n",
       "      <td>                            </td>\n",
       "      <td>         </td>\n",
       "      <td> observed</td>\n",
       "      <td> 10---Caltrain---2014</td>\n",
       "      <td>                            </td>\n",
       "      <td>   walk_egress</td>\n",
       "      <td>         </td>\n",
       "      <td>                           14673 walk_egress _1356</td>\n",
       "      <td>  14673 1356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              person_id  trip_list_id_num linkmode   A_id   B_id  linknum  \\\n",
       "3  10---Caltrain---2014                 2   access   1249  14661        0   \n",
       "4  10---Caltrain---2014                 2  transit  14661  14673        1   \n",
       "5  10---Caltrain---2014                 2   egress  14673   1356        2   \n",
       "\n",
       "            mode                     route_id    agency record_type  \\\n",
       "3     KNR_access                                           observed   \n",
       "4  commuter_rail  Caltrain_Millbrae Palo Alto  caltrain    observed   \n",
       "5    walk_egress                                           observed   \n",
       "\n",
       "              unique_id                  path_routes     path_modes  \\\n",
       "3  10---Caltrain---2014                                  KNR_access   \n",
       "4  10---Caltrain---2014  Caltrain_Millbrae Palo Alto  commuter_rail   \n",
       "5  10---Caltrain---2014                                 walk_egress   \n",
       "\n",
       "  path_agencies                                    path_components  \\\n",
       "3                                           1249 KNR_access _14661   \n",
       "4      caltrain  14661 commuter_rail Caltrain_Millbrae Palo Alt...   \n",
       "5                                          14673 walk_egress _1356   \n",
       "\n",
       "    path_stops  \n",
       "3   1249 14661  \n",
       "4  14661 14673  \n",
       "5   14673 1356  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs[obs['unique_id'] == '10---Caltrain---2014']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'index', u'person_id', u'person_trip_id', u'trip_list_id_num', u'pf_iteration', u'pathnum', u'linkmode', u'trip_id_num', u'A_id_num', u'B_id_num', u'A_seq', u'B_seq', u'pf_A_time', u'pf_B_time', u'pf_linktime min', u'pf_waittime min', u'linknum', u'A_id', u'B_id', u'A_lat', u'A_lon', u'B_lat', u'B_lon', u'trip_id', u'route_id', u'mode_num', u'mode', u'distance', u'chosen', u'bump_iter', u'bumpstop_boarded', u'alight_delay_min', u'new_A_time', u'new_B_time', u'new_linktime min', u'new_waittime min', u'missed_xfer', u'sim_cost', u'board_time', u'overcap', u'alight_time', u'iteration', u'record_type', u'unique_id', u'agency_id', u'agency', u'path_routes', u'path_modes', u'path_agencies', u'path_components', u'path_stops'], dtype='object')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosenpath_links[chosenpath_links['unique_id'] == '10---Caltrain---2014'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>person_id</th>\n",
       "      <th>person_trip_id</th>\n",
       "      <th>trip_list_id_num</th>\n",
       "      <th>pf_iteration</th>\n",
       "      <th>pathnum</th>\n",
       "      <th>linkmode</th>\n",
       "      <th>trip_id_num</th>\n",
       "      <th>A_id_num</th>\n",
       "      <th>B_id_num</th>\n",
       "      <th>...</th>\n",
       "      <th>alight_time</th>\n",
       "      <th>iteration</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>agency_id</th>\n",
       "      <th>agency</th>\n",
       "      <th>path_routes</th>\n",
       "      <th>path_modes</th>\n",
       "      <th>path_agencies</th>\n",
       "      <th>path_components</th>\n",
       "      <th>path_stops</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>record_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td>...</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             index  person_id  person_trip_id  trip_list_id_num  pf_iteration  \\\n",
       "record_type                                                                     \n",
       "model            3          3               3                 3             3   \n",
       "\n",
       "             pathnum  linkmode  trip_id_num  A_id_num  B_id_num     ...      \\\n",
       "record_type                                                         ...       \n",
       "model              3         3            3         3         3     ...       \n",
       "\n",
       "             alight_time  iteration  unique_id  agency_id  agency  \\\n",
       "record_type                                                         \n",
       "model                  3          3          3          3       3   \n",
       "\n",
       "             path_routes  path_modes  path_agencies  path_components  \\\n",
       "record_type                                                            \n",
       "model                  3           3              3                3   \n",
       "\n",
       "             path_stops  \n",
       "record_type              \n",
       "model                 3  \n",
       "\n",
       "[1 rows x 50 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosenpath_links[chosenpath_links['unique_id'] == '10---Caltrain---2014'].groupby('record_type').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # Isolate transit modes only, because all trips should have walk & transfer components\n",
    "    \n",
    "df['model_transit_modes'] = df['model_path_mode_list'].apply(\n",
    "    lambda row: [element for element in row if element not in non_transit_modes])\n",
    "df['obs_transit_modes'] = df['obs_path_mode_list'].apply(\n",
    "    lambda row: [element for element in row if element not in non_transit_modes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs_transit_modes</th>\n",
       "      <th>model_transit_modes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>            [commuter_rail]</td>\n",
       "      <td>        [commuter_rail]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>            [commuter_rail]</td>\n",
       "      <td> [local_bus, local_bus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>               [heavy_rail]</td>\n",
       "      <td>           [heavy_rail]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> [local_bus, commuter_rail]</td>\n",
       "      <td>        [commuter_rail]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>               [heavy_rail]</td>\n",
       "      <td>            [local_bus]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            obs_transit_modes     model_transit_modes\n",
       "0             [commuter_rail]         [commuter_rail]\n",
       "1             [commuter_rail]  [local_bus, local_bus]\n",
       "2                [heavy_rail]            [heavy_rail]\n",
       "3  [local_bus, commuter_rail]         [commuter_rail]\n",
       "4                [heavy_rail]             [local_bus]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['obs_transit_modes','model_transit_modes']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find the intersection between the chosen model/observed paths using different criteria\n",
    "# Which are in common between model and observed?\n",
    "\n",
    "# transit route IDs only\n",
    "df.apply(lambda row: all(i in row['model_path_route_list'] for i in row['obs_path_route_list']), axis=1)\n",
    "df['routes_intersection'] = [list(set(a).intersection(set(b))) for a, b in zip(df['model_path_route_list'], df['obs_path_route_list'])]\n",
    "\n",
    "# stops only\n",
    "df.apply(lambda row: all(i in row['model_path_stops_list'] for i in row['obs_path_stops_list']), axis=1)\n",
    "df['stops_intersection'] = [list(set(a).intersection(set(b))) for a, b in zip(df['model_path_stops_list'], df['obs_path_stops_list'])]\n",
    "\n",
    "# All Modes (including transfer, access/egress)\n",
    "df.apply(lambda row: all(i in row['model_path_mode_list'] for i in row['obs_path_mode_list']), axis=1)\n",
    "df['all_modes_intersection'] = [list(set(a).intersection(set(b))) for a, b in zip(df['model_path_mode_list'], df['obs_path_mode_list'])]\n",
    "\n",
    "# Transit modes only (type of vehicle taken and number of boardings)\n",
    "df.apply(lambda row: all(i in row['model_path_mode_list'] for i in row['obs_path_mode_list']), axis=1)\n",
    "df['transit_modes_intersection'] = [list(set(a).intersection(set(b))) for a, b in zip(df['model_transit_modes'], df['obs_transit_modes'])]\n",
    "\n",
    "# Agency Intersection\n",
    "df.apply(lambda row: all(i in row['model_path_agencies_list'] for i in row['obs_path_agencies_list']), axis=1)\n",
    "df['agency_intersection'] = \\\n",
    "    [list(set(a).intersection(set(b))) for a, b in zip(df['model_path_agencies_list'], \n",
    "        df['obs_path_agencies_list'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Exact Match of path routes, modes, & components\n",
    "# Isolate rows (trip legs) with matching path routes\n",
    "complete_route_match = df[df['path_routes_observed'] == df['path_routes_model']]\n",
    "complete_mode_match = df[df['path_modes_observed'] == df['path_modes_model']]\n",
    "complete_agency_match = df[df['path_agencies_observed'] == df['path_agencies_model']]\n",
    "complete_stop_match = df[df['path_stops_observed'] == df['path_stops_model']]\n",
    "\n",
    "complete_route_match['complete_route_match'] = 1\n",
    "complete_mode_match['complete_mode_match'] = 1\n",
    "complete_agency_match['complete_agency_match'] = 1\n",
    "complete_stop_match['complete_stop_match'] = 1\n",
    "\n",
    "# Add new columns to the larger dataframe indicating if the row is a complete match\n",
    "df = pd.merge(df, complete_mode_match[['unique_id','complete_mode_match']], how='left', on='unique_id')\n",
    "\n",
    "\n",
    "df = pd.merge(df, complete_route_match[['unique_id','complete_route_match']], how='left', on='unique_id')\n",
    "df = pd.merge(df, complete_agency_match[['unique_id','complete_agency_match']], how='left', on='unique_id')\n",
    "df = pd.merge(df, complete_stop_match[['unique_id','complete_stop_match']], how='left', on='unique_id')\n",
    "\n",
    "for field in ['mode','route','agency', 'stop']:\n",
    "    df['complete_'+field+'_match']=  df['complete_'+field+'_match'].replace('nan',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we find the percent of trips with matching routes or partial matching routes\n",
    "\n",
    "# Join the filtered data to the original results\n",
    "df['common_route_count'] = [len(row) for row in df['routes_intersection']]\n",
    "df['common_mode_count'] = [len(row) for row in df['all_modes_intersection']]\n",
    "df['common_transit_mode_count'] = [len(row) for row in df['transit_modes_intersection']]\n",
    "df['common_agency_count'] = [len(row) for row in df['agency_intersection']]\n",
    "df['common_stop_count'] = [len(row) for row in df['stops_intersection']]\n",
    "\n",
    "# How many rows have at least one mode in common?\n",
    "df['partial_mode_match'] = [1 if row > 0 else 0 for row in df['common_mode_count']]\n",
    "df['partial_transit_mode_match'] = [1 if row > 0 else 0 for row in df['common_transit_mode_count']]\n",
    "df['partial_route_match'] = [1 if row > 0 else 0 for row in df['common_route_count']]\n",
    "df['partial_agency_match'] = [1 if row > 0 else 0 for row in df['common_agency_count']]\n",
    "df['partial_stop_match'] = [1 if row > 0 else 0 for row in df['common_stop_count']]\n",
    "\n",
    "# Export\n",
    "df.to_csv(OUTPUT_DIR + r'/path_intersection.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check if observed path is in pathset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pathset_links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Add a field to the new_pathset that lists the pathnum\n",
    "# pathset_links['pathnum'] = pathset_links.index.get_level_values(1)\n",
    "\n",
    "# Join paths based on comparison_field, as defined in script header\n",
    "# Resulting df is merge of all observed paths that have a corresponding path in the pathset for their unique_id\n",
    "# observed paths with no corresponding path in pathset will have NaN for fields \"_pathset\" suffix\n",
    "newdf = pd.merge(observed_path, pathset_paths, how='left',\n",
    "          left_on=['unique_id',comparison_field],right_on=['unique_id',comparison_field], suffixes=['_obs','_pathset'])\n",
    "\n",
    "# Join this data with the pathset path file to get pf_probability associated with the observed path\n",
    "# newdf = pd.merge(df, pathset_paths[['unique_id','pathnum','pf_probability']], \n",
    "#                  left_on=['unique_id','pathnum'], right_on=['unique_id','pathnum'],\n",
    "#                  how='left')\n",
    "\n",
    "# Fields with NaN marked as no match since no matching path was found in pathset\n",
    "newdf['probability'] = newdf['pf_probability'].fillna('no_match')\n",
    "\n",
    "# Grab the highest and lowest probabilities from pathset paths\n",
    "# want to test that the observed path has a reasonably high probability\n",
    "max_prob = newdf.groupby('unique_id').max()['probability']\n",
    "min_prob = newdf.groupby('unique_id').min()['probability']\n",
    "\n",
    "# Reshape those results and export to dataframe\n",
    "prob_export = pd.DataFrame([max_prob,min_prob]).T\n",
    "prob_export.columns = ['max_prob','min_prob']\n",
    "\n",
    "\n",
    "# Reformat at binary to indicate whether a path was found in the pathset\n",
    "prob_export['path_exists'] = prob_export['max_prob'].apply(lambda row_value: 0 if row_value == 'no_match' else 1)\n",
    "prob_export.to_csv('temp_prob_export.csv')\n",
    "\n",
    "# Create a variabale to indicate if the max probability of the observed path\n",
    "# is over a given threshold, as defined at top of script\n",
    "try:\n",
    "    prob_export.ix[prob_export['max_prob'] >= threshold, 'above_threshold'] = 1\n",
    "    prob_export.ix[prob_export['max_prob'] < threshold, 'above_threshold'] = 0\n",
    "    prob_export.ix[prob_export['max_prob'] == 'no_match', 'above_threshold'] = -1\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# export the results probabilities, path_existence, threshold data,\n",
    "# also add the modeled and observed (chosen) path characteristics\n",
    "prob_export['unique_id'] = prob_export.index\n",
    "\n",
    "tempdf = pd.merge(observed_path,modeled_path,on='unique_id',suffixes=['_obs','_model'],how='left')\n",
    "export_df = pd.merge(prob_export,tempdf,on='unique_id',how='left')\n",
    "\n",
    "export_df['person_id'] = export_df['unique_id'].apply(lambda row: row.split(\"_\")[0])\n",
    "export_df['trip_list_id_num'] = export_df['unique_id'].apply(lambda row: row.split(\"_\")[-1])\n",
    "\n",
    "export_df.to_csv(OUTPUT_DIR + '\\path_comparison.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33905065815715996"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_df['path_exists'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path_exists       1.00000\n",
       "above_threshold   0.49794\n",
       "dtype: float64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_df[export_df['max_prob'] != 'no_match'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010271240526525728"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['complete_route_match'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19315915436777023"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['complete_stop_match'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2847028320702034"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['complete_agency_match'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
